{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Making sure that we got all the data\ndef folder_size(path='.'):\n    total = 0\n    for entry in os.scandir(path):\n        if entry.is_file():\n            total += entry.stat().st_size\n        elif entry.is_dir():\n            total += folder_size(entry.path)\n    return total\n\n\nprint(\"Size in bytes: \" + str(folder_size('/kaggle/input/'))) # This is the size in bytes\nprint(\"Size in GB: \" +str(folder_size('/kaggle/input/') / (1024**3))) # This is the size in gigabytes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport scipy.ndimage\nimport skimage.filters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preprocessing steps\n\n#laplacian filtering\nfiltered = scipy.ndimage.filters.laplace(img_array[:, :10000, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(filtered)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import skimage.io\nimport cv2\n\ndef load_and_resize_image(img_path):\n    \"\"\"\n    Edited from https://www.kaggle.com/xhlulu/panda-resize-and-save-train-data\n    \"\"\"\n    biopsy = skimage.io.MultiImage(img_path)\n    return cv2.resize(biopsy[-1], (512, 512))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = load_and_resize_image('/content/0005f7aaab2800f6170c399693a96917.tiff')\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered = scipy.ndimage.filters.laplace(img)\nplt.imshow(filtered)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.color import rgb2gray\n\ngrayscale_img = rgb2gray(img)\nthreshold = skimage.filters.threshold_otsu(grayscale_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(grayscale_img, cmap = 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(grayscale_img > threshold, cmap = 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_patches(image, window_size=200, stride=200):\n\n  max_width, max_height = image.shape[0], image.shape[1]\n  regions_container = []\n\n  i = 0\n  while window_size + stride*i <= max_height:\n      j = 0\n\n      while window_size + stride*j <= max_width:            \n          x_top_left_pixel = j * stride\n          y_top_left_pixel = i * stride\n\n          patch = image[\n              x_top_left_pixel : x_top_left_pixel + window_size,\n              y_top_left_pixel : y_top_left_pixel + window_size\n          ]\n\n          if np.sum(patch) == window_size * window_size * 255:\n            regions_container.append(patch)\n\n\n          j += 1\n\n      i += 1\n\n  return regions_container","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_patches(grayscale_img, window_size=200, stride=200))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load functions\n\nimport re\n\ndef Filter(string, substr): \n    return [str for str in string if\n             any(sub in str for sub in substr)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# unzip all image files\n\nimport zipfile, os\n\nbase_dir = \"/kaggle/\"\n\nfor file in os.listdir(base_dir):   # get the list of files\n    if zipfile.is_zipfile(file): # if it is a zipfile, extract it\n        with zipfile.ZipFile(file) as item: # treat the file as a zip\n           item.extractall()  # extract it in the working directory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load packages, both original images and masks\nimport os, shutil\nimport tifffile as tiff\nimport os\n#import pydicom as dcm\nimport matplotlib.pyplot as plt\nfrom skimage.filters import threshold_otsu\nfrom skimage.color import rgb2gray\nimport tifffile as tiff\nimport csv\nimport pandas as pd\nimport skimage.io\nfrom skimage.transform import resize, rescale\nimport numpy as np\nimport cv2\nfrom skimage import data\nfrom skimage import filters\nimport matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\n\nbase_dir = \"/content/\"\n\nlist_of_files = os.listdir(base_dir)\nlist_of_zips = Filter(list_of_files, ['zip'])\nlist_of_files = set(list_of_files) - set(list_of_zips)\nlist_of_files=Filter(list_of_files, ['tiff'])\nlist_masks = Filter(list_of_files, ['mask'])\nlist_imgs = set(list_of_files) - set(list_masks)\nlist_imgs =  list(list_imgs)\n\nvalidation_proportion = 0.5\n\nlist_masks_train = list_masks[:int(round(len(list_masks)*0.5,0))]\nlist_masks_val = list_masks[int(round(len(list_masks)*0.5,0)):]\nlist_imgs_train = list_imgs[:int(round(len(list_imgs)*0.5,0))]\nlist_imgs_val = list_imgs[int(round(len(list_imgs)*0.5,0)):]\n\nprint('total training images:', len(list_imgs_train))\nprint('total validation images:', len(list_imgs_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imagecodecs\n!pip install Tifffile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load images and labels\n# 2 types of labels: 1) multiple: isup_grade 2) binary: benign/malignant\n\nimport os\nimport matplotlib.pyplot as plt\nfrom skimage.filters import threshold_otsu\nfrom skimage.color import rgb2gray\nimport tifffile as tiff\nimport csv\nimport pandas as pd\nimport skimage.io\nfrom skimage.io import imread\nfrom skimage.transform import resize, rescale\nimport numpy as np\nimport cv2\nfrom skimage import data\nfrom skimage import filters\nimport matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\n\nimg_height = 1024\nimg_width = 1024\n\nbase_dir = \"/content/\"\ntrain_dir = os.path.join(base_dir, 'train/')\n\n# read label file\nlabels = pd.read_csv(os.path.join(base_dir,'train.csv'), sep=',')\nlabels = labels.to_numpy() # labels[:,2] 0 image_id, 1 data_provider, 2 isup_grade, 3 gleason_score\nbenign_malignant = np.zeros((labels.shape[0],1))\nlabels = np.concatenate((labels, benign_malignant), axis=1)\nlabels[:,4] = (labels[:,2]>0)*1 # labels[:,4] convert to binary benign(0)/malignant(1) for binary classification\n\n#--------------\n\n# read images\nlist_of_imgs = list_imgs_train # list_masks_train\ntrain_labels_multiple = np.empty([len(list_of_imgs)]) # create label array   \ntrain_labels_binary = np.empty([len(list_of_imgs)])\n\n# create 3D train array\nimgs_train = np.zeros((len(list_of_imgs),img_height,img_width))\n\nprint(\"start building input array\")\nfor i in range(0,len(list_of_imgs)): # stack images into appropriate 3D training array\n    img_num = i\n    img_path = os.path.join(base_dir,list_of_imgs[img_num])\n    print(img_path)\n    #img_mask = skimage.io.MultiImage(img_path)\n    #print(img_mask.shape)\n    img_mask = tiff.imread(img_path)\n    #img_mask = cv2.resize(img_mask[-1], (img_height, img_width))\n    img_mask = cv2.resize(img_mask[:,:,0], (img_height, img_width))\n    imgs_train[i,:,:]=img_mask.reshape(1,img_height,img_width)\n    \n    # if the image is in 'train.csv', add to labels array\n    train_labels_multiple[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),2]\n    train_labels_binary[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),4]\n    print(i)\n    \ntrain_labels_multiple = to_categorical(train_labels_multiple)\ntrain_labels_binary = to_categorical(train_labels_binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create validation set\n\nbase_dir = \"C:/Users/Qi/Desktop/Education/Stanford MS/BIOMED 260 Biomedical Imaging/Final Project/Kaggle Data/\"\nvalidation_dir = os.path.join(base_dir, 'validation/')\n\n# read images\nlist_of_imgs = os.listdir(validation_dir)\nval_labels_multiple = np.empty([len(list_of_imgs)]) # create label array   \nval_labels_binary = np.empty([len(list_of_imgs)])\n\n# create 3D validation array\nimgs_val = np.zeros((len(list_of_imgs),img_height,img_width))\n\n#for i in range(0,10):\nfor i in range(0,len(imgs_val)-1): # stack images into appropriate 3D training array\n    img_num = i\n    img_path = os.path.join(validation_dir,list_of_imgs[img_num])\n    img_mask = tiff.imread(img_path)\n    #img_mask = cv2.resize(img_mask[-1], (img_height, img_width))\n    img_mask = cv2.resize(img_mask[:,:,0], (img_height, img_width))\n    imgs_val[i,:,:]=img_mask.reshape(1,img_height,img_width)\n    \n    # if the image is in 'train.csv', add to labels array\n    val_labels_multiple[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),2]\n    val_labels_binary[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),4]\n    print(list_of_imgs[i].split('.')[0],\" \",labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),4])\n    \nval_labels_multiple = to_categorical(val_labels_multiple)\nval_labels_binary = to_categorical(val_labels_binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up a convnet model\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras import regularizers\n\n# model: multiple classification; model1: binary classification\nNum_neurous_layer1 = 32\nNum_neurous_layer2 = 32\nNum_neurous_layer3 = 32\nNum_neurous_layer4 = 32\nNum_classifications = len(set(labels[:,2])) # 0-5, total of 6 categories\nKernel_height = 5\nKernel_width = Kernel_height\nPooling_height = 5\nPooling_width = Pooling_height \n\n# multiple classification model\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(Num_neurous_layer1, (Kernel_height, Kernel_width), activation='relu', input_shape=(img_height, img_width, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(Num_neurous_layer2, (Kernel_height, Kernel_width), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(Num_neurous_layer3, (Kernel_height, Kernel_width), activation='relu'))\nmodel.add(layers.Flatten())\n# add regularizer\nmodel.add(layers.Dense(Num_neurous_layer4,kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n# add dropout\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(Num_classifications, activation='softmax'))\nmodel.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# binary classification model\nmodel1 = models.Sequential()\nmodel1.add(layers.Conv2D(Num_neurous_layer1, (Kernel_height, Kernel_width), activation='relu', input_shape=(img_height, img_width, 1)))\nmodel1.add(layers.MaxPooling2D((2, 2)))\nmodel1.add(layers.Conv2D(Num_neurous_layer2, (Kernel_height, Kernel_width), activation='relu'))\nmodel1.add(layers.MaxPooling2D((2, 2)))\nmodel1.add(layers.Conv2D(Num_neurous_layer3, (Kernel_height, Kernel_width), activation='relu'))\nmodel1.add(layers.Flatten())\n# add regularizer\nmodel1.add(layers.Dense(Num_neurous_layer4,kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n# add dropout\nmodel1.add(layers.Dropout(0.1))\nmodel1.add(layers.Dense(2, activation='sigmoid'))\nmodel1.compile(optimizer=optimizers.RMSprop(lr=1e-4),loss='binary_crossentropy',metrics=['accuracy'])\n\nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train binary classification model\nfrom keras.preprocessing.image import ImageDataGenerator\n\nbatch_size_input = 100\nepochs_input = 20\n\nimgs_train = imgs_train.reshape((imgs_train.shape[0], imgs_train.shape[1], imgs_train.shape[2], 1))\nimgs_val = imgs_val.reshape((imgs_val.shape[0], imgs_val.shape[1], imgs_val.shape[2], 1))\n\n# augmentation\ndatagen = ImageDataGenerator(rotation_range=30,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.1,zoom_range=0.1,fill_mode='nearest')\ndatagen.fit(imgs_train)\n\n# regular model fit\n#history = model1.fit(imgs_train, train_labels_binary, epochs=epochs_input, batch_size=batch_size_input, validation_data=(imgs_val,val_labels_binary))\n\nhistory = model1.fit_generator(datagen.flow(imgs_train, train_labels_binary,batch_size=batch_size_input),epochs=epochs_input,validation_data=(imgs_val,val_labels_binary))\n\nmodel1.save('PC_binary.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying curves of loss and accuracy during training\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train multiple classification model\n\nhistory = model.fit_generator(datagen.flow(imgs_train, train_labels_multiple,batch_size=batch_size_input),epochs=epochs_input,validation_data=(imgs_val,val_labels_multiple))\nmodel.save('PC_gleason_score.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use HW3 data as an example to illustrate regular NN from extracted features rather than images\nimport numpy as np\n\nfeatures = pd.read_csv('features_matrix.csv', sep=',')\ntrain_set = pd.read_csv('mass_case_description_train_set.csv', sep=',')\nid_side_view = train_set.iloc[:,0]+\"_\"+train_set.iloc[:,2]+\"_\"+train_set.iloc[:,3]\ntrain_set['id_side_view'] = id_side_view\nfull_data = pd.merge(features,train_set,'inner',left_on=['id_side_view'],right_on=['id_side_view'])\nfull_data = full_data.to_numpy()\nfull_data = full_data[full_data[:,22]=='MLO',:] # 554 rows of features and labels\n\n# normalize features by column\nfeatures = full_data[:,1:19] # margin, shape, columns 24/25\nfeatures = np.float32(features)\nmean = features.mean(axis=0)\nfeatures -= mean\nstd = features.std(axis=0)\nfeatures /= std\n\nlabels = full_data[:,26]\nlabels = to_categorical(labels)\n\ncut_off = 400\nfeatures_train = features[0:cut_off,:]\nfeatures_val = features[cut_off:,:]\nlabels_train = labels[0:cut_off,:]\nlabels_val = labels[cut_off:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DNN model, takes extracted features as input\nmodel = models.Sequential()\nmodel.add(layers.Dense(features_train.shape[1]*2, activation='relu', input_shape=(features_train.shape[1],)))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(features_train.shape[1]*2, kernel_regularizer=regularizers.l2(0.001),activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(features_train.shape[1]*2, kernel_regularizer=regularizers.l2(0.001),activation='relu'))\nmodel.add(layers.Dense(labels_train.shape[1], activation='softmax'))\n\nmodel.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train multiple classification model\nepochs_input = 30\nbatch_size_input = 50\n\nhistory = model.fit(features_train,labels_train,epochs=epochs_input,batch_size=batch_size_input,validation_data=(features_val, labels_val))\nmodel.save('PC_features_gleason_score.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying curves of loss and accuracy during training\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification that takes original images as inputs:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# divide mask images into training, validation and test sets\n\nimport os, shutil\n\nimgs_path = \"C:/Users/Qi/Desktop/Education/Stanford MS/BIOMED 260 Biomedical Imaging/Final Project/Kaggle Data/Orig_imgs/\"\nlist_of_imgs = os.listdir(imgs_path)\nbase_dir = \"C:/Users/Qi/Desktop/Education/Stanford MS/BIOMED 260 Biomedical Imaging/Final Project/Kaggle Data/Orig_imgs/\"\n\ntrain_dir = os.path.join(base_dir, 'train')\nos.mkdir(train_dir)\nvalidation_dir = os.path.join(base_dir, 'validation')\nos.mkdir(validation_dir)\ntest_dir = os.path.join(base_dir, 'test')\nos.mkdir(test_dir)\nlist_of_imgs = os.listdir(imgs_path)\n\n# assign number of images in each set\nnum_training_imgs = 500\nnum_validation_imgs = 200\nnum_test_imgs = 200\n\nfor i in range(0,num_training_imgs):\n    src = os.path.join(imgs_path, list_of_imgs[i])\n    dst = os.path.join(train_dir, list_of_imgs[i])\n    shutil.copyfile(src, dst)\n\nfor i in range(num_training_imgs,(num_training_imgs+num_validation_imgs)):\n    src = os.path.join(imgs_path, list_of_imgs[i])\n    dst = os.path.join(validation_dir, list_of_imgs[i])\n    shutil.copyfile(src, dst)\n\nfor i in range((num_validation_imgs+num_training_imgs),(num_training_imgs+num_validation_imgs+num_test_imgs)):\n    src = os.path.join(imgs_path, list_of_imgs[i])\n    dst = os.path.join(test_dir, list_of_imgs[i])\n    shutil.copyfile(src, dst)\n\nprint('total training images:', len(os.listdir(train_dir)))\nprint('total validation images:', len(os.listdir(validation_dir)))\nprint('total validation images:', len(os.listdir(test_dir)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load images and labels\n# create training array\n# 2 types of labels: 1) multiple: isup_grade 2) binary: benign/malignant\n\nimport os\nimport pydicom as dcm\nimport matplotlib.pyplot as plt\nfrom skimage.filters import threshold_otsu\nfrom skimage.color import rgb2gray\nimport tifffile as tiff\nimport csv\nimport pandas as pd\nimport skimage.io\nfrom skimage.transform import resize, rescale\nimport numpy as np\nimport cv2\nfrom skimage import data\nfrom skimage import filters\nimport matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\nfrom PIL import Image\nimport openslide\n\nimg_height = 1024\nimg_width = 1024\n\nbase_dir = \"C:/Users/Qi/Desktop/Education/Stanford MS/BIOMED 260 Biomedical Imaging/Final Project/Kaggle Data/Orig_imgs/\"\ntrain_dir = os.path.join(base_dir, 'train/')\n\n# read label file\nlabels = pd.read_csv(os.path.join(base_dir,'train.csv'), sep=',')\nlabels = labels.to_numpy() # labels[:,2] 0 image_id, 1 data_provider, 2 isup_grade, 3 gleason_score\nbenign_malignant = np.zeros((labels.shape[0],1))\nlabels = np.concatenate((labels, benign_malignant), axis=1)\nlabels[:,4] = (labels[:,2]>0)*1 # labels[:,4] convert to binary benign(0)/malignant(1) for binary classification\n\n# read images\nlist_of_imgs = os.listdir(train_dir)\ntrain_labels_multiple = np.empty([len(list_of_imgs)]) # create label array   \ntrain_labels_binary = np.empty([len(list_of_imgs)])\n\n# create 3D training array\nimgs_train = np.zeros((len(list_of_imgs),img_height,img_width))\n\nfor i in range(0,len(list_of_imgs)): # stack images into appropriate 3D training array\n    img_num = i\n    img_path = os.path.join(train_dir,list_of_imgs[img_num])\n    img_mask = openslide.open_slide(img_path)\n    img_mask = np.array(img_mask.read_region((0,0),1, (img_mask.level_dimensions[1][0],img_mask.level_dimensions[1][1])))\n    img_mask = cv2.resize(img_mask[:,:,2], (img_height, img_width))\n    imgs_train[i,:,:]=img_mask.reshape(1,img_height,img_width)\n    \n    # if the image is in 'train.csv', add to labels array\n    train_labels_multiple[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),2]\n    train_labels_binary[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),4]\n    print(i)\n    \ntrain_labels_multiple = to_categorical(train_labels_multiple)\ntrain_labels_binary = to_categorical(train_labels_binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create validation set\n\nvalidation_dir = os.path.join(base_dir, 'validation/')\n\n# read images\nlist_of_imgs = os.listdir(validation_dir)\nval_labels_multiple = np.empty([len(list_of_imgs)]) # create label array   \nval_labels_binary = np.empty([len(list_of_imgs)])\n\n# create 3D validation array\nimgs_val = np.zeros((len(list_of_imgs),img_height,img_width))\n\nfor i in range(0,len(imgs_val)-1): # stack images into appropriate 3D validation array\n    img_num = i\n    img_path = os.path.join(validation_dir,list_of_imgs[img_num])\n    img_mask = openslide.open_slide(img_path)\n    img_mask = np.array(img_mask.read_region((0,0),1, (img_mask.level_dimensions[1][0],img_mask.level_dimensions[1][1])))\n    img_mask = cv2.resize(img_mask[:,:,2], (img_height, img_width))\n    imgs_val[i,:,:]=img_mask.reshape(1,img_height,img_width)\n    \n    # if the image is in 'train.csv', add to labels array\n    val_labels_multiple[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),2]\n    val_labels_binary[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),4]\n    #print(list_of_imgs[i].split('.')[0],\" \",labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),4])\n    \nval_labels_multiple = to_categorical(val_labels_multiple)\nval_labels_binary = to_categorical(val_labels_binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create test set\n\ntest_dir = os.path.join(base_dir, 'test/')\n\n# read images\nlist_of_imgs = os.listdir(test_dir)\ntest_labels_multiple = np.empty([len(list_of_imgs)]) # create label array   \ntest_labels_binary = np.empty([len(list_of_imgs)])\n\n# create 3D validation array\nimgs_test = np.zeros((len(list_of_imgs),img_height,img_width))\n\nfor i in range(0,len(imgs_test)-1): # stack images into appropriate 3D validation array\n    img_num = i\n    img_path = os.path.join(test_dir,list_of_imgs[img_num])\n    img_mask = tiff.imread(img_path)\n    img_mask = cv2.resize(img_mask[:,:,0], (img_height, img_width))\n    imgs_test[i,:,:]=img_mask.reshape(1,img_height,img_width)\n    \n    test_labels_multiple[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),2]\n    test_labels_binary[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),4]\n    #print(list_of_imgs[i].split('.')[0],\" \",labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),4])\n    \ntest_labels_multiple = to_categorical(test_labels_multiple)\ntest_labels_binary = to_categorical(test_labels_binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(imgs_train.shape)\nprint(train_labels_multiple.shape)\nprint(train_labels_binary.shape)\n\nnp.save('img_train_107.npy', imgs_train)\nnp.save('img_train_labels_multiple_107.npy', train_labels_multiple)\nnp.save('img_train_labels_binary_107.npy', train_labels_binary)\n\nnp.save('img_val_27.npy', imgs_val)\nnp.save('img_val_labels_multiple_27.npy', val_labels_multiple)\nnp.save('img_val_labels_binary_27.npy', val_labels_binary)\n\n#np.save('img_mask_test_200.npy', imgs_test)\n#np.save('img_mask_test_labels_multiple_200.npy', test_labels_multiple)\n#np.save('img_mask_test_labels_binary_200.npy', test_labels_binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dispaly masked images\n\nplt.figure(1)\nplt.subplot(131)\nplt.imshow(img_mask[:,:,0], cmap=\"gray\")\nplt.subplot(132)\nplt.imshow(img_mask[:,:,1], cmap=\"gray\")\nplt.subplot(133)\nplt.imshow(img_mask[:,:,2], cmap=\"gray\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up a convnet model\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras import regularizers\n\n# model: multiple classification; model1: binary classification\nNum_neurous_layer1 = 32\nNum_neurous_layer2 = 32\nNum_neurous_layer3 = 32\nNum_neurous_layer4 = 32\nNum_classifications = len(set(labels[:,2])) # 0-5, total of 6 categories\nKernel_height = 5\nKernel_width = Kernel_height\nPooling_height = 5\nPooling_width = Pooling_height\n\n# multiple classification model\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(Num_neurous_layer1, (Kernel_height, Kernel_width), activation='relu', input_shape=(img_height, img_width, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(Num_neurous_layer2, (Kernel_height, Kernel_width), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(Num_neurous_layer3, (Kernel_height, Kernel_width), activation='relu'))\nmodel.add(layers.Flatten())\n# add regularizer\nmodel.add(layers.Dense(Num_neurous_layer4,kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n# add dropout\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(Num_classifications, activation='softmax'))\nmodel.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# binary classification model\nmodel1 = models.Sequential()\nmodel1.add(layers.Conv2D(Num_neurous_layer1, (Kernel_height, Kernel_width), activation='relu', input_shape=(img_height, img_width, 1)))\nmodel1.add(layers.MaxPooling2D((2, 2)))\nmodel1.add(layers.Conv2D(Num_neurous_layer2, (Kernel_height, Kernel_width), activation='relu'))\nmodel1.add(layers.MaxPooling2D((2, 2)))\nmodel1.add(layers.Conv2D(Num_neurous_layer3, (Kernel_height, Kernel_width), activation='relu'))\nmodel1.add(layers.Flatten())\n# add regularizer\nmodel1.add(layers.Dense(Num_neurous_layer4,kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n# add dropout\nmodel1.add(layers.Dropout(0.1))\nmodel1.add(layers.Dense(2, activation='sigmoid'))\nmodel1.compile(optimizer=optimizers.RMSprop(lr=1e-4),loss='binary_crossentropy',metrics=['accuracy'])\n\nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train binary classification model\nfrom keras.preprocessing.image import ImageDataGenerator\n\nbatch_size_input = 20\nepochs_input = 10\n\nimgs_train = imgs_train.reshape((imgs_train.shape[0], imgs_train.shape[1], imgs_train.shape[2], 1))\nimgs_val = imgs_val.reshape((imgs_val.shape[0], imgs_val.shape[1], imgs_val.shape[2], 1))\n\n# augmentation\ndatagen = ImageDataGenerator(rotation_range=30,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.1,zoom_range=0.1,fill_mode='nearest')\ndatagen.fit(imgs_train)\n\n# regular model fit\n#history = model1.fit(imgs_train, train_labels_binary, epochs=epochs_input, batch_size=batch_size_input, validation_data=(imgs_val,val_labels_binary))\n\nhistory = model1.fit_generator(datagen.flow(imgs_train, train_labels_binary,batch_size=batch_size_input),epochs=epochs_input,validation_data=(imgs_val,val_labels_binary))\n\nmodel1.save('PC_binary.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying curves of loss and accuracy during training\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train multiple classification model\n\nhistory = model.fit_generator(datagen.flow(imgs_train, train_labels_multiple,batch_size=batch_size_input),epochs=epochs_input,validation_data=(imgs_val,val_labels_multiple))\nmodel.save('PC_gleason_score.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying curves of loss and accuracy during training\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification that takes masks as inputs:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# divide mask images into training, validation and test sets\n\nimport os, shutil\n\nimgs_path = \"C:/Users/Qi/Desktop/Education/Stanford MS/BIOMED 260 Biomedical Imaging/Final Project/Kaggle Data/Imgs_mask/\"\nlist_of_imgs = os.listdir(imgs_path)\nbase_dir = \"C:/Users/Qi/Desktop/Education/Stanford MS/BIOMED 260 Biomedical Imaging/Final Project/Kaggle Data/\"\n\ntrain_dir = os.path.join(base_dir, 'train')\nos.mkdir(train_dir)\nvalidation_dir = os.path.join(base_dir, 'validation')\nos.mkdir(validation_dir)\ntest_dir = os.path.join(base_dir, 'test')\nos.mkdir(test_dir)\nlist_of_imgs = os.listdir(imgs_path)\n\n# assign number of images in each set\nnum_training_imgs = 500\nnum_validation_imgs = 200\nnum_test_imgs = 200\n\nfor i in range(0,num_training_imgs):\n    src = os.path.join(imgs_path, list_of_imgs[i])\n    dst = os.path.join(train_dir, list_of_imgs[i])\n    shutil.copyfile(src, dst)\n\nfor i in range(num_training_imgs,(num_training_imgs+num_validation_imgs)):\n    src = os.path.join(imgs_path, list_of_imgs[i])\n    dst = os.path.join(validation_dir, list_of_imgs[i])\n    shutil.copyfile(src, dst)\n\nfor i in range((num_validation_imgs+num_training_imgs),(num_training_imgs+num_validation_imgs+num_test_imgs)):\n    src = os.path.join(imgs_path, list_of_imgs[i])\n    dst = os.path.join(test_dir, list_of_imgs[i])\n    shutil.copyfile(src, dst)\n\nprint('total training images:', len(os.listdir(train_dir)))\nprint('total validation images:', len(os.listdir(validation_dir)))\nprint('total validation images:', len(os.listdir(test_dir)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load images and labels\n# create training array\n# 2 types of labels: 1) multiple: isup_grade 2) binary: benign/malignant\n\nimport os\nimport pydicom as dcm\nimport matplotlib.pyplot as plt\nfrom skimage.filters import threshold_otsu\nfrom skimage.color import rgb2gray\nimport tifffile as tiff\nimport csv\nimport pandas as pd\nimport skimage.io\nfrom skimage.transform import resize, rescale\nimport numpy as np\nimport cv2\nfrom skimage import data\nfrom skimage import filters\nimport matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\n\nimg_height = 1024\nimg_width = 1024\n\nbase_dir = \"C:/Users/Qi/Desktop/Education/Stanford MS/BIOMED 260 Biomedical Imaging/Final Project/Kaggle Data/\"\ntrain_dir = os.path.join(base_dir, 'train/')\n\n# read label file\nlabels = pd.read_csv(os.path.join(base_dir,'train.csv'), sep=',')\nlabels = labels.to_numpy() # labels[:,2] 0 image_id, 1 data_provider, 2 isup_grade, 3 gleason_score\nbenign_malignant = np.zeros((labels.shape[0],1))\nlabels = np.concatenate((labels, benign_malignant), axis=1)\nlabels[:,4] = (labels[:,2]>0)*1 # labels[:,4] convert to binary benign(0)/malignant(1) for binary classification\n\n# read images\nlist_of_imgs = os.listdir(train_dir)\ntrain_labels_multiple = np.empty([len(list_of_imgs)]) # create label array   \ntrain_labels_binary = np.empty([len(list_of_imgs)])\n\n# create 3D training array\nimgs_train = np.zeros((len(list_of_imgs),img_height,img_width))\n\nfor i in range(0,len(list_of_imgs)): # stack images into appropriate 3D training array\n    img_num = i\n    img_path = os.path.join(train_dir,list_of_imgs[img_num])\n    img_mask = tiff.imread(img_path)\n    img_mask = cv2.resize(img_mask[:,:,0], (img_height, img_width))\n    imgs_train[i,:,:]=img_mask.reshape(1,img_height,img_width)\n    \n    # if the image is in 'train.csv', add to labels array\n    train_labels_multiple[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),2]\n    train_labels_binary[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),4]\n    print(i)\n    \ntrain_labels_multiple = to_categorical(train_labels_multiple)\ntrain_labels_binary = to_categorical(train_labels_binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create validation set\n\nvalidation_dir = os.path.join(base_dir, 'validation/')\n\n# read images\nlist_of_imgs = os.listdir(validation_dir)\nval_labels_multiple = np.empty([len(list_of_imgs)]) # create label array   \nval_labels_binary = np.empty([len(list_of_imgs)])\n\n# create 3D validation array\nimgs_val = np.zeros((len(list_of_imgs),img_height,img_width))\n\nfor i in range(0,len(imgs_val)-1): # stack images into appropriate 3D validation array\n    img_num = i\n    img_path = os.path.join(validation_dir,list_of_imgs[img_num])\n    img_mask = tiff.imread(img_path)\n    img_mask = cv2.resize(img_mask[:,:,0], (img_height, img_width))\n    imgs_val[i,:,:]=img_mask.reshape(1,img_height,img_width)\n    \n    # if the image is in 'train.csv', add to labels array\n    val_labels_multiple[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),2]\n    val_labels_binary[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),4]\n    #print(list_of_imgs[i].split('.')[0],\" \",labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),4])\n    \nval_labels_multiple = to_categorical(val_labels_multiple)\nval_labels_binary = to_categorical(val_labels_binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create test set\n\ntest_dir = os.path.join(base_dir, 'test/')\n\n# read images\nlist_of_imgs = os.listdir(test_dir)\ntest_labels_multiple = np.empty([len(list_of_imgs)]) # create label array   \ntest_labels_binary = np.empty([len(list_of_imgs)])\n\n# create 3D validation array\nimgs_test = np.zeros((len(list_of_imgs),img_height,img_width))\n\nfor i in range(0,len(imgs_test)-1): # stack images into appropriate 3D validation array\n    img_num = i\n    img_path = os.path.join(test_dir,list_of_imgs[img_num])\n    img_mask = tiff.imread(img_path)\n    img_mask = cv2.resize(img_mask[:,:,0], (img_height, img_width))\n    imgs_test[i,:,:]=img_mask.reshape(1,img_height,img_width)\n    \n    test_labels_multiple[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),2]\n    test_labels_binary[i]=labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),4]\n    #print(list_of_imgs[i].split('.')[0],\" \",labels[(np.argwhere(labels == list_of_imgs[i].split('.')[0].split('_')[0])[0,0]),4])\n    \ntest_labels_multiple = to_categorical(test_labels_multiple)\ntest_labels_binary = to_categorical(test_labels_binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(imgs_test.shape)\n#print(test_labels_multiple.shape)\n#print(test_labels_binary.shape)\nimport os\nimport pydicom as dcm\nimport matplotlib.pyplot as plt\nfrom skimage.filters import threshold_otsu\nfrom skimage.color import rgb2gray\nimport tifffile as tiff\nimport csv\nimport pandas as pd\nimport skimage.io\nfrom skimage.transform import resize, rescale\nimport numpy as np\nimport cv2\nfrom skimage import data\nfrom skimage import filters\nimport matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\n\nimg_height = 1024\nimg_width = 1024\n\nbase_dir = \"C:/Users/Qi/Desktop/Education/Stanford MS/BIOMED 260 Biomedical Imaging/Final Project/Kaggle Data/\"\nlabels = pd.read_csv(os.path.join(base_dir,'train.csv'), sep=',')\nlabels = labels.to_numpy() # labels[:,2] 0 image_id, 1 data_provider, 2 isup_grade, 3 gleason_score\nbenign_malignant = np.zeros((labels.shape[0],1))\nlabels = np.concatenate((labels, benign_malignant), axis=1)\nlabels[:,4] = (labels[:,2]>0)*1 # labels[:,4] convert to binary benign(0)/malignant(1) for binary classification\n\nimgs_train = np.load('img_mask_train_500.npy')\ntrain_labels_multiple = np.load('img_mask_train_labels_multiple_500.npy')\ntrain_labels_binary = np.load('img_mask_train_labels_binary_500.npy')\n\nimgs_val = np.load('img_mask_val_200.npy')\nval_labels_multiple = np.load('img_mask_val_labels_multiple_200.npy')\nval_labels_binary = np.load('img_mask_val_labels_binary_200.npy')\n\n#np.save('img_mask_train_500.npy', imgs_train)\n#np.save('img_mask_train_labels_multiple_500.npy', train_labels_multiple)\n#np.save('img_mask_train_labels_binary_500.npy', train_labels_binary)\n\n#np.save('img_mask_val_200.npy', imgs_val)\n#np.save('img_mask_val_labels_multiple_200.npy', val_labels_multiple)\n#np.save('img_mask_val_labels_binary_200.npy', val_labels_binary)\n\n#np.save('img_mask_test_200.npy', imgs_test)\n#np.save('img_mask_test_labels_multiple_200.npy', test_labels_multiple)\n#np.save('img_mask_test_labels_binary_200.npy', test_labels_binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dispaly masked images\n\nplt.figure(1)\nplt.subplot(131)\nplt.imshow(img_mask[:,:,0], cmap=\"gray\")\nplt.subplot(132)\nplt.imshow(img_mask[:,:,1], cmap=\"gray\")\nplt.subplot(133)\nplt.imshow(img_mask[:,:,2], cmap=\"gray\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up a convnet model\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras import regularizers\n\n# model: multiple classification; model1: binary classification\nNum_neurous_layer1 = 32\nNum_neurous_layer2 = 32\nNum_neurous_layer3 = 32\nNum_neurous_layer4 = 32\nNum_classifications = len(set(labels[:,2])) # 0-5, total of 6 categories\nKernel_height = 5\nKernel_width = Kernel_height\nPooling_height = 5\nPooling_width = Pooling_height \n\n# multiple classification model\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(Num_neurous_layer1, (Kernel_height, Kernel_width), activation='relu', input_shape=(img_height, img_width, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(Num_neurous_layer2, (Kernel_height, Kernel_width), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(Num_neurous_layer3, (Kernel_height, Kernel_width), activation='relu'))\nmodel.add(layers.Flatten())\n# add regularizer\nmodel.add(layers.Dense(Num_neurous_layer4,kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n# add dropout\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(Num_classifications, activation='softmax'))\nmodel.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# binary classification model\nmodel1 = models.Sequential()\nmodel1.add(layers.Conv2D(Num_neurous_layer1, (Kernel_height, Kernel_width), activation='relu', input_shape=(img_height, img_width, 1)))\nmodel1.add(layers.MaxPooling2D((2, 2)))\nmodel1.add(layers.Conv2D(Num_neurous_layer2, (Kernel_height, Kernel_width), activation='relu'))\nmodel1.add(layers.MaxPooling2D((2, 2)))\nmodel1.add(layers.Conv2D(Num_neurous_layer3, (Kernel_height, Kernel_width), activation='relu'))\nmodel1.add(layers.Flatten())\n# add regularizer\nmodel1.add(layers.Dense(Num_neurous_layer4,kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n# add dropout\nmodel1.add(layers.Dropout(0.1))\nmodel1.add(layers.Dense(2, activation='sigmoid'))\nmodel1.compile(optimizer=optimizers.RMSprop(lr=1e-4),loss='binary_crossentropy',metrics=['accuracy'])\n\nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train binary classification model\nfrom keras.preprocessing.image import ImageDataGenerator\n\nbatch_size_input = 50\nepochs_input = 5\n\nimgs_train = imgs_train.reshape((imgs_train.shape[0], imgs_train.shape[1], imgs_train.shape[2], 1))\nimgs_val = imgs_val.reshape((imgs_val.shape[0], imgs_val.shape[1], imgs_val.shape[2], 1))\n\n# augmentation\ndatagen = ImageDataGenerator(rotation_range=30,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.1,zoom_range=0.1,fill_mode='nearest')\ndatagen.fit(imgs_train)\n\n# regular model fit\n#history = model1.fit(imgs_train, train_labels_binary, epochs=epochs_input, batch_size=batch_size_input, validation_data=(imgs_val,val_labels_binary))\n\nhistory = model1.fit_generator(datagen.flow(imgs_train, train_labels_binary,batch_size=batch_size_input),epochs=epochs_input,validation_data=(imgs_val,val_labels_binary))\n\n#model1.save('PC_binary.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying curves of loss and accuracy during training\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train multiple classification model\n\nhistory = model.fit_generator(datagen.flow(imgs_train, train_labels_multiple,batch_size=batch_size_input),epochs=epochs_input,validation_data=(imgs_val,val_labels_multiple))\n#model.save('PC_gleason_score.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying curves of loss and accuracy during training\n\nimport matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}